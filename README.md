Offline AI Voice Assistant with Local LLM:

An offline, privacy-first AI voice assistant built using Python.  
Supports speech recognition, intent detection, system commands, and natural language conversation using a local LLM.
Requires Ollama running locally
POINTS TO NOTE:
No cloud APIs used
Designed for privacy and offline usage

Features:
- Speech-to-Text (STT)
- Intent Detection
- Tool Execution (Time, Browser Automation)
- Local LLM Integration (Phi-3 via Ollama)
- Text-to-Speech (TTS)
- Modular & Fault-Tolerant Architecture
- Works on CPU-only systems

Tech Stack Used:
Python, SpeechRecognition, pyttsx3, Ollama, Phi-3 LLM, Offline AI

SEtup: 
pip install -r requirements.txt
python main.py
